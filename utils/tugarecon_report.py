# --------------------------------------------------------------------------------------------------
# TugaRecon â€“ Intelligence Report Generator (Corrected)
# Author: Skynet0x01 2020-2026
# License: GNU GPLv3
# --------------------------------------------------------------------------------------------------

from pathlib import Path
import subprocess
from datetime import datetime
import json
import shutil
import os

# -------------------------------------------------------
def load_json(path):
    try:
        with open(path) as f:
            return json.load(f)
    except Exception as e:
        print(f"[!] Failed to load JSON {path}: {e}")
        return None

# -------------------------------------------------------
def sanitize_unicode(text: str) -> str:
    replacements = {
        "ðŸŸ¢": "[ALIVE]",
        "ðŸ”´": "[DEAD]",
        "ðŸŸ¡": "[MEDIUM]",
        "ðŸ§ ": "[INTEL]",
        "â€¢": "-",
    }
    for k, v in replacements.items():
        text = text.replace(k, v)
    return text


# -------------------------------------------------------
def render_attack_paths_section(md: list, base_dir):
    path = os.path.join(base_dir, "attack_paths.json")
    if not os.path.exists(path):
        return
    with open(path, "r", encoding="utf-8") as f:
        attack_paths = json.load(f)
    if not attack_paths:
        return
    md.append("## Plausible Attack Paths\n")
    for idx, ap in enumerate(attack_paths, 1):
        md.append(f"### Attack Path #{idx}")
        md.append(" â†’ ".join(ap["path"]))
        md.append(f"- Total Cost: {ap['total_cost']}")
        md.append(f"- Final Impact: {ap['final_impact']}")
        md.append(f"- Confidence: {ap['confidence']}\n")

def render_worst_case(md: list, base_dir):
    path = os.path.join(base_dir, "worst_case.json")
    if not os.path.exists(path):
        return
    with open(path, "r", encoding="utf-8") as f:
        worst_case = json.load(f)
    md.append("## Worst Case Scenario\n")
    md.append(" â†’ ".join(worst_case["path"]))
    md.append(f"- Estimated Impact: {worst_case['final_impact']}")
    md.append(f"- Confidence: {worst_case['confidence']}\n")

# -------------------------------------------------------
def generate_report(base_dir: Path, generate_pdf=False):
    """
    Generate Markdown & PDF intelligence report.
    base_dir = .../results/domain/date/report
    """

    report = []
    now = datetime.utcnow().isoformat()
    scan_root = base_dir.parent
    target = scan_root.parent.name

    base_dir.mkdir(parents=True, exist_ok=True)

    # -------------------------------------------------------
    # Header
    report.append("# TugaRecon Intelligence Report\n")
    report.append("**Generated by TugaRecon â€“ Advanced Reconnaissance & Intelligence Framework**  ")
    report.append("Author: skynet0x01  ")
    report.append("License: GNU GPLv3  ")
    report.append(f"Report generated on: {now} UTC  ")
    report.append(f"\nTarget: `{target}`\n")
    report.append("---\n")

    # -------------------------------------------------------
    # Priority Targets
    prio = scan_root / "attack_surface" / "priority_targets.txt"
    report.append("## Priority Targets")
    if prio.exists() and prio.read_text().strip():
        report.append("```\n" + prio.read_text().strip() + "\n```")
    else:
        report.append("_No priority targets detected._")

    # -------------------------------------------------------
    # Attack Surface Summary
    summary = scan_root / "attack_surface" / "attack_surface_summary.txt"
    report.append("\n## Attack Surface Summary")
    if summary.exists() and summary.read_text().strip():
        report.append("```\n" + summary.read_text().strip() + "\n```")
    else:
        report.append("_No summary available._")

    # -------------------------------------------------------
    # Semantic Intelligence
    semantic_path = scan_root / "semantic_results.json"
    semantic = load_json(semantic_path)

    report.append("\n## High Impact Semantic Targets")
    if semantic:
        count = 0
        for entry in semantic:
            impact = entry.get("impact_score", entry.get("impact", 0))
            if impact < 1:
                continue
            subdomain = entry.get("subdomain", "unknown")
            url = entry.get("url", "N/A")
            status = entry.get("status", "N/A")
            scheme = entry.get("scheme", "N/A")
            tags = ", ".join(entry.get("tags", [])) if entry.get("tags") else "None"
            priority = entry.get("priority", entry.get("_priority", "LOW"))

            report.append(
                f"- **{subdomain}** (impact={impact}, priority={priority})\n"
                f"  - URL: {url}\n"
                f"  - Status: {status} | Scheme: {scheme}\n"
                f"  - Tags: {tags}\n"
            )
            count += 1
        if count == 0:
            report.append("_No high impact semantic targets detected._")
    else:
        report.append("_No semantic data available._")

    # -------------------------------------------------------
    # Render Attack Paths
    #from tugarecon_report_sections import render_attack_paths_section, render_worst_case
    render_attack_paths_section(report, scan_root / "attack_surface")
    render_worst_case(report, scan_root / "attack_surface")

    # -------------------------------------------------------
    # Temporal Intelligence
    diff = load_json(scan_root / "scan_diff.json")
    report.append("\n## Temporal Changes")
    if diff:
        for k, section in [("new", "Newly Discovered Assets"),
                           ("escalated", "Escalated Risk Assets"),
                           ("disappeared", "Disappeared Assets")]:
            if diff.get(k):
                report.append(f"\n### {section}")
                for item in diff[k]:
                    sub = item.get("subdomain", "unknown")
                    impact = item.get("impact_score", item.get("impact", 0))
                    priority = item.get("priority", item.get("_priority", "LOW"))
                    report.append(f"- {sub} â†’ impact_score: {impact}, priority: {priority}")
    else:
        report.append("_No temporal data available._")

    # -------------------------------------------------------
    # Probe Statistics
    web = scan_root / "probe" / "web_hosts.txt"
    dead = scan_root / "probe" / "dead_hosts.txt"
    report.append("\n## Probe Statistics")
    if web.exists():
        alive_count = len(web.read_text().splitlines())
        report.append(f"- Alive hosts: {alive_count}")
    if dead.exists():
        dead_count = len(dead.read_text().splitlines())
        report.append(f"- Dead hosts: {dead_count}")

    # -------------------------------------------------------
    # Save Markdown
    md_path = base_dir / "report.md"
    md_path.write_text(sanitize_unicode("\n".join(report)))

    # -------------------------------------------------------
    # Generate PDF
    pdf_path = None
    if generate_pdf:
        pdf_path = base_dir / "report.pdf"
        if not shutil.which("pandoc"):
            print("[!] Pandoc not found. Install pandoc to generate PDF reports.")
            return md_path, None
        try:
            result = subprocess.run(
                ["pandoc", str(md_path), "-o", str(pdf_path), "--pdf-engine=xelatex"],
                capture_output=True, text=True
            )
            if result.returncode != 0:
                print("[!] PDF generation failed:")
                print(result.stderr)
                pdf_path = None
            else:
                print(f"[âœ…] PDF generated successfully: {pdf_path}")
        except Exception as e:
            print(f"[!] PDF generation failed: {e}")
            pdf_path = None

    return md_path, pdf_path
